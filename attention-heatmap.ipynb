{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 3 (Encoder Decoder )","metadata":{}},{"cell_type":"markdown","source":"# Importing the libraries","metadata":{}},{"cell_type":"code","source":"#importing the necessary libraries\n\nfrom torch.utils.data import Dataset\nimport xml.etree.ElementTree as ET\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport torch\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom IPython.display import clear_output\nimport random\nimport wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:58:51.257580Z","iopub.execute_input":"2023-05-21T10:58:51.257996Z","iopub.status.idle":"2023-05-21T10:59:07.336286Z","shell.execute_reply.started":"2023-05-21T10:58:51.257961Z","shell.execute_reply":"2023-05-21T10:59:07.335023Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.font_manager import FontProperties\nimport numpy","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:09.475409Z","iopub.execute_input":"2023-05-21T10:59:09.476232Z","iopub.status.idle":"2023-05-21T10:59:09.484145Z","shell.execute_reply.started":"2023-05-21T10:59:09.476186Z","shell.execute_reply":"2023-05-21T10:59:09.482900Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Installing wandb**","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade wandb","metadata":{"execution":{"iopub.status.busy":"2023-05-12T03:18:20.243879Z","iopub.execute_input":"2023-05-12T03:18:20.244310Z","iopub.status.idle":"2023-05-12T03:18:39.601730Z","shell.execute_reply.started":"2023-05-12T03:18:20.244270Z","shell.execute_reply":"2023-05-12T03:18:39.600246Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.0)\nCollecting wandb\n  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.20.0)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.28.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.15.0\n    Uninstalling wandb-0.15.0:\n      Successfully uninstalled wandb-0.15.0\nSuccessfully installed wandb-0.15.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Uploading the data","metadata":{}},{"cell_type":"code","source":"\"\"\"KEY : a1d8ccb0c91879ee96665642bf53e088782f937b  \"\"\"\n\"\"\"                            Uploading the data               \"\"\"\n\nCSV_file = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_train.csv')\n#print(CSV_file)\n\n\"\"\"                           Loading the Dataset                         \"\"\"\n\nX_train = CSV_file.iloc[:, 0].values\n#print(X_train)\nY_train = CSV_file.iloc[:, 1].values\n#print(Y_train)\nhindi_alphabets_ = [chr(alpha) for alpha in range(2304, 2432)]\nCSV_file_test = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_valid.csv')\n#print(CSV_file)\n\n\"\"\"                           Loading the Dataset                         \"\"\"\n\nX_test = CSV_file_test.iloc[:, 0].values\n#print(X_train)\nY_test = CSV_file_test.iloc[:, 1].values\n#print(Y_train)\n\nprint(\" f1 Number of training samples: \", len(X_train))\nprint(\"f1 Number of test samples: \", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:31.564602Z","iopub.execute_input":"2023-05-21T10:59:31.565145Z","iopub.status.idle":"2023-05-21T10:59:31.690439Z","shell.execute_reply.started":"2023-05-21T10:59:31.565101Z","shell.execute_reply":"2023-05-21T10:59:31.689252Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":" f1 Number of training samples:  51199\nf1 Number of test samples:  4095\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data preprocessing ","metadata":{}},{"cell_type":"code","source":"# english and hindi dictionary\n\n\nhindi_alphabets =hindi_alphabets_\ndevice_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# from a - z creating a array\neng_alphabets = 'abcdefghijklmnopqrstuvwxyz'\n\n#total number of charchters in english and hindi vocabulary\ntotal_character_in_english = 26\ntotal_character_in_hindi = 129\npad_char = '-P-'\n\neng_index = {pad_char: 0}\n\n# making the dictionary for the english and hindi\nfor i, c in enumerate(eng_alphabets):\n    print(i+1,\" \",end=\"\")\n    eng_index[c] = i+1\n    print(eng_index[c],\" \",end=\"\")\nprint(eng_index)\n\nsize_b = 0 \nintial_size = 0\nhindi_size = len(hindi_alphabets) + size_b - intial_size\nprint(hindi_size)\nhindi_index = {pad_char: 0}\n\nfor i, c in enumerate(hindi_alphabets):\n    #print(i+1,\" \",end=\"\")\n    hindi_index[c] = i+1\n    #print(hindi_index[c],\" \",end=\"\")\nprint(hindi_index)\n\n#converting into english vector representation\n\ndef word_representation(intial_word,word_size, word, l2i, device = 'cpu'):\n    temp_ = len(word)+1\n    temp_1 = len(l2i)\n    rep = torch.zeros(temp_, 1, temp_1).to(device)\n    special_zero = 0\n    for letter_index_to_another, letter in enumerate(word):\n        pos = l2i[letter]\n        #print(\"convert\")\n        rep[letter_index_to_another][special_zero][pos] = 1\n    pad_pos = l2i[pad_char]\n    #print(pad_pos)\n    rep[letter_index_to_another+1][special_zero][pad_pos] = 1\n    return rep\nvalue_of_max = 50\n#converting into hindi vector representation\ndef transform_representation(intial_word,word_size,word, l2i, device = 'cpu'):\n    one = 1\n    #print(one)\n    temp_ = [len(word)+1, one]\n    ch = pad_char\n    word_represent = torch.zeros(temp_, dtype=torch.long).to(device)\n    for letter_index_to_another, letter in enumerate(word):\n        pos = l2i[letter]\n        zero = 0\n        word_represent[letter_index_to_another][zero] = pos\n    word_represent[letter_index_to_another+1][zero] = l2i[ch]\n    #print(\"converted\",one)\n    return word_represent\n\nvalue_of_max = 50\neng, hindi = X_train,Y_train\nprint(eng[0])\neng_rep = word_representation('-p-',26,eng[0], eng_index)\nprint(eng, eng_rep)\nprint(hindi[0])\nhindi_gt = transform_representation('-p-',129,hindi[0], hindi_index)\nprint(hindi, hindi_gt)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:35.549283Z","iopub.execute_input":"2023-05-21T10:59:35.549734Z","iopub.status.idle":"2023-05-21T10:59:35.677738Z","shell.execute_reply.started":"2023-05-21T10:59:35.549693Z","shell.execute_reply":"2023-05-21T10:59:35.676434Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9  10  10  11  11  12  12  13  13  14  14  15  15  16  16  17  17  18  18  19  19  20  20  21  21  22  22  23  23  24  24  25  25  26  26  {'-P-': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n128\n{'-P-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\nbindhya\n['bindhya' 'kirankant' 'yagyopaveet' ... 'asahmaton' 'sulgaayin'\n 'anchuthengu'] tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n\n        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\nबिन्द्या\n['बिन्द्या' 'किरणकांत' 'यज्ञोपवीत' ... 'असहमतों' 'सुलगायीं' 'अंचुतेंगु'] tensor([[45],\n        [64],\n        [41],\n        [78],\n        [39],\n        [78],\n        [48],\n        [63],\n        [ 0]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# DATA Class","metadata":{}},{"cell_type":"code","source":"\n# Class DATA : used for preprocess the data\nclass Data(Dataset):\n    # constructor to load the data first \n\n    def __init__(self, X_train,Y_train):\n        self.hindi_words = Y_train\n        self.eng_words  = X_train\n        length_ = len(self.eng_words)\n        master = list(range(length_))\n        self.shuffle_indices = master\n        self.index_to_start = 0\n        random.shuffle(self.shuffle_indices)\n\n    # randomly picking the data point help to create a batch    \n    def __getitem__(self, index):\n        a= []\n        b = []\n        word_of_english = self.eng_words[index] \n        word_of_hindi = self.hindi_words[index]\n        return word_of_english, word_of_hindi    \n    \n    # return the desired item given the index as parameter from the dataset\n    def return_item(self, index):\n        english = self.eng_words[index]\n        hindi= self.hindi_words[index]\n        return english,hindi \n    \n    # returning the batch of 2 words in our case it is english and hindi\n    def func_batch(self, batch_size, array,x_,y_):\n        batch = []\n        batch_ = batch_size\n        self.zero = 0\n        end = self.index_to_start + batch_\n        \n        if end >= len(self.eng_words) and self.zero != batch_:\n            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n            self.zero = (batch_ - 1)\n            self.start_batch_to_array= []\n            end = len(self.eng_words)\n        result = batch.copy()\n        for i in range(self.shuffle_start_index, end):\n            result.append(array[self.shuffle_indices[i]])\n        return result\n    \n    # given a batch return those many number of data\n    def get_batch(self, batch_size, postprocess = True):\n        eng_batch = self.func_batch(batch_size, self.eng_words,0,1)\n        hindi_batch = self.func_batch(batch_size, self.hindi_words,0,1)\n        self.shuffle_start_index = self.shuffle_start_index + batch_size \n        self.shuffle_start_index += 1\n        batch_ = 1\n        if self.shuffle_start_index >= len(self.eng_words) and self.zero != len(self.eng_words):\n            random.shuffle(self.shuffle_indices)\n            self.zero = (batch_ - 1)\n            self.shuffle_start_index = 0\n\n        # return the batch    \n        return eng_batch, hindi_batch\n    \ntrain_data = Data(X_train,Y_train)\ntest_data = Data(X_test,Y_test)    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:40.555938Z","iopub.execute_input":"2023-05-21T10:59:40.556329Z","iopub.status.idle":"2023-05-21T10:59:40.632109Z","shell.execute_reply.started":"2023-05-21T10:59:40.556299Z","shell.execute_reply":"2023-05-21T10:59:40.631210Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Attention class for RNN and GRU","metadata":{}},{"cell_type":"code","source":"#class constructor\n\nclass EncoderDecoder_Attention(nn.Module):\n    #constructor\n    \n    def __init__(self,model_type, input_size, hidden_size, output_size, num_layers=1, dropout=0, bidirectional=False, verbose=False):\n        super(EncoderDecoder_Attention, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        #choice between GRU and RNN\n        \n        if(model_type == \"GRU\"):\n            self.encoder = nn.GRU(input_size, hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=bidirectional)\n            self.decoder = nn.GRU(hidden_size*2, hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=bidirectional)\n        if(model_type == \"RNN\"):\n            self.encoder = nn.RNN(input_size, hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=bidirectional)\n            self.decoder = nn.RNN(hidden_size*2, hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=bidirectional)\n        \n        # U V and W, matrix for the need of calculating attention\n        \n        self.h2o = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=2)\n        \n        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size, 1)\n        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n        \n        \n    def forward(self, input, limit = value_of_max, device = 'cpu', ground_truth = None,asked = False):\n        \n        # encoder\n        one = 1\n        two = 2\n        encoder_outputs, hidden = self.encoder(input)\n        out_e  = encoder_outputs\n        encoder_outputs = encoder_outputs.view(one - two, self.hidden_size)\n\n        decoder_state = hidden\n        decoder_input = torch.zeros(two - one, one, self.output_size).to(device)\n        zero = 0\n        \n        output_answer = []\n        predict = []\n        attention_weight_matrix = []\n        U = self.U(encoder_outputs)\n        count = 1\n        for i in range(0,limit,1):\n            \n            W = self.W(decoder_state.view(one, one-two).repeat(encoder_outputs.shape[zero], one+zero))\n            V = self.attn(torch.tanh(U + W))\n            attn_weights = F.softmax(V.view(one, zero - one), dim = two - one) \n            attention_weight_matrix.append(attn_weights.squeeze().detach().cpu().numpy())\n           \n            attn_applied = torch.bmm(attn_weights.unsqueeze(zero),\n                                 encoder_outputs.unsqueeze(zero))\n            \n            embedding = self.out2hidden(decoder_input)\n            decoder_input = torch.cat((embedding[two -two], attn_applied[zero]), zero+one).unsqueeze(zero)\n                \n            out, decoder_state = self.decoder(decoder_input, decoder_state)\n            temp_out = out\n            di_state = decoder_state    \n            out = self.h2o(decoder_state)\n            answer_out = out\n            out = self.softmax(out)\n            temp = temp_out\n            count = (1+ count)%10\n            output_answer.append(out.view(one, one-two))\n            \n            index_of_array = i\n            maximum_index = torch.argmax(out, two, keepdim=True)\n            if not ground_truth is None and one == one+zero:\n                maximum_index = ground_truth[index_of_array].reshape(one+zero, one, two-one)\n            one_hot_vector = torch.zeros(out.shape, device=device)\n            one_hot_vector.scatter_(two, maximum_index, one)\n            decoder_input = one_hot_vector.detach()\n            din = decoder_input\n        if(asked == True):\n            return output_answer , np.array(attention_weight_matrix)\n        return output_answer\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:43.739058Z","iopub.execute_input":"2023-05-21T10:59:43.740144Z","iopub.status.idle":"2023-05-21T10:59:43.764826Z","shell.execute_reply.started":"2023-05-21T10:59:43.740077Z","shell.execute_reply":"2023-05-21T10:59:43.763426Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Attention LSTM Class","metadata":{}},{"cell_type":"code","source":"class EncoderDecoder_Attention_LSTM(nn.Module):\n    \n    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.0, bidirectional=False, verbose=False):\n        super(EncoderDecoder_Attention_LSTM, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_layers\n        self.bidirectional = bidirectional\n        \n        self.encoder = nn.LSTM(input_size, hidden_size, num_layers=num_layers, \n                                        dropout=dropout, bidirectional=bidirectional)\n        self.decoder = nn.LSTM(hidden_size*2, hidden_size, num_layers=num_layers, \n                                        dropout=dropout, bidirectional=bidirectional)\n        \n        self.h2o = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=2)\n        \n        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size, 1)\n        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n        \n        \n    def forward(self, input, limit =value_of_max, device = 'cpu', ground_truth = None,asked = False):\n        one = 1\n        minone = -1\n        zero = 0\n        # encoder\n        encoder_outputs, (hidden, cell) = self.encoder(input)\n        two = 2\n        if self.bidirectional:\n            hidden = hidden.view(self.num_layers, two, one - two, self.hidden_size)\n            cell = cell.view(self.num_layers, two, minone, self.hidden_size)\n            \n            # concatenate the hidden state of the last layer \n            \n            hidden = torch.cat((hidden[minone,zero], hidden[one-two,one]), dim=one).unsqueeze(zero)\n            cell = torch.cat((cell[zero - one,zero], cell[minone,one]), dim=two - one).unsqueeze(zero)\n        else:\n            hidden = hidden[minone,:,:].unsqueeze(two -two)\n            cell = cell[minone,:,:].unsqueeze(zero)\n        encoder_outputs = encoder_outputs.view(minone, self.hidden_size)\n        \n\n        \n        # decoder\n        decoder_state = (hidden, cell)\n        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n        \n        outputs = []\n        predict = []\n        attention_weight_matrix = []\n        U = self.U(encoder_outputs)\n        \n        for i in range(0,limit,1):\n            \n            W = self.W(decoder_state[zero].view(one, -1).repeat(encoder_outputs.shape[zero], one))\n            V = self.attn(torch.tanh(U + W))\n            attn_weights = F.softmax(V.view(one, minone), dim = one) \n            attention_weight_matrix.append(attn_weights.squeeze().detach().cpu().numpy())\n           \n            attn_applied = torch.bmm(attn_weights.unsqueeze(zero),\n                                 encoder_outputs.unsqueeze(zero))\n            \n            embedding = self.out2hidden(decoder_input)\n            decoder_input = torch.cat((embedding[zero], attn_applied[zero]), one).unsqueeze(zero)\n\n                \n            out, decoder_state = self.decoder(decoder_input, decoder_state)\n                \n            out = self.h2o(decoder_state[zero])\n            temp_out = out\n            out = self.softmax(out)\n            temp_out = out\n            outputs.append(out.view(one, minone))\n            ans  = temp_out\n            \n            maximum_index = torch.argmax(out, two, keepdim=True)\n            if not ground_truth is None and zero == 0 and two == 2:\n                maximum_index = ground_truth[i].reshape(one, zero+one, two - one)\n            one_hot_vector = torch.zeros(out.shape, device=device)\n            temp_store = one_hot_vector\n            one_hot_vector.scatter_(two+zero,maximum_index, one+zero) \n            \n            decoder_input = one_hot_vector.detach()\n            din_in  = decoder_input\n        if(asked == True):\n            return outputs , np.array(attention_weight_matrix)\n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:47.579734Z","iopub.execute_input":"2023-05-21T10:59:47.580101Z","iopub.status.idle":"2023-05-21T10:59:47.604985Z","shell.execute_reply.started":"2023-05-21T10:59:47.580072Z","shell.execute_reply":"2023-05-21T10:59:47.603589Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def vector_representation(english_word,hindi_word,net, word,limit, device='cpu'):\n    net.eval().to(device)\n    temp_word = []\n    temp_word.append('@')\n    temp_word.append('#')\n    word = word_representation('pad',26,word, eng_index)\n    count = 1\n    count+=2\n    output = net(word, limit)\n    if(count > 4):\n        count+=1\n        print(count)\n    return output\nnet = EncoderDecoder_Attention(\"GRU\",len(eng_index), 256, len(hindi_index), num_layers=1)\n     \nout = vector_representation('english','hindi',net, 'india', 30)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:50.836992Z","iopub.execute_input":"2023-05-21T10:59:50.837384Z","iopub.status.idle":"2023-05-21T10:59:50.946269Z","shell.execute_reply.started":"2023-05-21T10:59:50.837354Z","shell.execute_reply":"2023-05-21T10:59:50.945395Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"#training function takes the couple of parameter and train on GPU\n\ndef training_model(algorithm,X_train, Y_train , net, lr = 0.01, no_of_batches = 100, batch_size = 10,  display_freq=5, device = 'cpu'):\n    #model is being taken to GPU\n    \n    momentum = 0.9\n    net = net.to(device)\n    \n    #slecting the Loss FUnction and the optimzer \n    \n    criterion = nn.NLLLoss(ignore_index = -1)\n    if(algorithm == 'Adam') :   \n        opt = optim.Adam(net.parameters(), lr=lr)\n    if(algorithm == 'NAdam') :   \n        opt = optim.NAdam(net.parameters(), lr=lr)\n    if(algorithm == 'RMSprop'):    \n        opt = optim.RMSprop(net.parameters(), lr=lr)    \n    variable = 2\n    teacher_force_upto = no_of_batches//variable\n    \n    loss_arr = np.zeros(no_of_batches + 1)\n    \n    #for how many batches to train\n    one = 1\n    display = True\n    \n    for i in range(0,no_of_batches,1):\n        value_stored = loss_arr[i]*i\n        print(i)\n        loss_arr[i+1] = (value_stored + batch(X_train,Y_train,net, opt, criterion, batch_size, device = device, teacher_force = i< teacher_force_upto))/(i+1)\n        acc = calc_accuracy(net, device)\n        acc_train = calc_accuracy_train(net, device)\n        #wandb.log({\"Loss\": loss_arr[i+1] , \"Validation accuracy\": acc,\"Training accuracy\": acc_train,\"Epochs\": i})\n        frequency_ = i%display_freq\n        if frequency_ == display_freq-one and True == display:\n            clear_output(wait = True)\n            print('Iteration',i,'Loss',loss_arr[i],'accuracy',acc)\n            plt.figure()\n            plt.plot(loss_arr[1:i],'-*')\n            plt.xlabel('Iteration')\n            plt.ylabel('Loss')\n            plt.show()\n            print('\\n')\n            \n    \n    return loss_arr","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:54.013936Z","iopub.execute_input":"2023-05-21T10:59:54.014941Z","iopub.status.idle":"2023-05-21T10:59:54.028392Z","shell.execute_reply.started":"2023-05-21T10:59:54.014901Z","shell.execute_reply":"2023-05-21T10:59:54.026361Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# backward propagation function\n\ndef batch(X_train ,Y_train ,net , opt, criterion, batch_size, device = 'cuda', teacher_force = False):\n    \n    net.train().to(device)\n    opt.zero_grad()\n    eng_batch, hindi_batch = X_train,Y_train\n    loss_array_pre = []\n    total_loss = 0\n    value_of_ground = False\n    \n        \n    for i in range(0,batch_size,1):\n        \n        input = word_representation('pad',26,eng_batch[i], eng_index, device)\n        word = transform_representation('pad',129,hindi_batch[i], hindi_index, device)\n        if(teacher_force == True):\n            value_of_ground = word\n        else:\n            value_of_ground = None\n        outputs = net(input, word.shape[0], device, ground_truth = value_of_ground)\n        \n        for index, output in enumerate(outputs):\n            temp_var =word[index]\n            temp_batch = batch_size\n            loss = criterion(output, temp_var) /temp_batch \n            loss.backward(retain_graph = True)\n            total_loss =total_loss + loss\n        \n    opt.step()\n    answer = total_loss/batch_size\n    a = 0\n    count = True\n    if(count == True):\n        a+=1\n        \n    return answer","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:59:57.338430Z","iopub.execute_input":"2023-05-21T10:59:57.339786Z","iopub.status.idle":"2023-05-21T10:59:57.350930Z","shell.execute_reply.started":"2023-05-21T10:59:57.339733Z","shell.execute_reply":"2023-05-21T10:59:57.349860Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#predicting the output of english word to hindi word\n\ndef hindi_output_word(net, word, device = 'cpu'):\n    hindi_to_english = ''\n    net = net.eval().to(device)\n    one = 1\n    outputs = vector_representation('english','hindi',net, word, 30, device)\n    hindi_output = ''\n    i = 0\n    zero = 0\n    out_temp = []\n    for out in outputs:\n        out_temp.append(i)\n        i+=1\n        val, indices = out.topk(one)\n        i-=1\n        out_temp.append(i)\n        index = indices.tolist()[zero][one-one]\n        if index == 0 and one == 1:\n            break\n        hindi_char = hindi_alphabets[index+1]\n        hindi_output =hindi_output + hindi_char\n    print(word + ' - ' + hindi_output)\n    return hindi_output","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:00:00.039591Z","iopub.execute_input":"2023-05-21T11:00:00.040015Z","iopub.status.idle":"2023-05-21T11:00:00.048913Z","shell.execute_reply.started":"2023-05-21T11:00:00.039982Z","shell.execute_reply":"2023-05-21T11:00:00.047767Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy Calculation ","metadata":{}},{"cell_type":"code","source":"#calculation of accuracy\n\ndef calc_accuracy_train(net, device = 'cpu'):\n    zero = 0\n    net = net.eval().to(device)\n    outputs = []\n    predictions = []\n    accuracy = 0\n    percentage = 0\n    for i in range(0,1024,1):\n        eng, hindi = train_data[i]\n        english_word = eng\n        hindi_word = hindi\n        word = transform_representation('pad',129,hindi, hindi_index, device)\n        correct_words = np.array(5)\n        outputs = vector_representation('english','hindi',net, eng, word.shape[0])\n        correct = 0\n        sum = len(X_train)\n        for index, out in enumerate(outputs):\n            val, indices = out.topk(1)\n            sum+=correct\n            hindi_position = indices.tolist()[0]\n            if hindi_position[zero] == word[index][zero]:\n                correct = correct + 1\n        \n        accuracy =accuracy + (correct/word.shape[0])\n    sum = 0\n    accuracy =accuracy / 1024\n    return accuracy\n\n# accuracy on validation set \n\ndef calc_accuracy(net, device = 'cpu'):\n    zero = 0\n    net = net.eval().to(device)\n    outputs = []\n    predictions = []\n    accuracy = 0\n    percentage = 0\n    for i in range(0,1024,1):\n        eng, hindi = test_data[i]\n        english_word = eng\n        hindi_word = hindi\n        word = transform_representation('pad',129,hindi, hindi_index, device)\n        correct_words = np.array(5)\n        outputs = vector_representation('english','hindi',net, eng, word.shape[0])\n        correct = 0\n        sum = len(X_train)\n        for index, out in enumerate(outputs):\n            val, indices = out.topk(1)\n            sum+=correct\n            hindi_position = indices.tolist()[0]\n            if hindi_position[zero] == word[index][zero]:\n                correct = correct + 1\n        \n        accuracy =accuracy + (correct/word.shape[0])\n    sum = 0\n    accuracy =accuracy / 1024\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:00:03.003046Z","iopub.execute_input":"2023-05-21T11:00:03.003476Z","iopub.status.idle":"2023-05-21T11:00:03.019409Z","shell.execute_reply.started":"2023-05-21T11:00:03.003443Z","shell.execute_reply":"2023-05-21T11:00:03.018091Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"just to see class i working","metadata":{}},{"cell_type":"code","source":"net = EncoderDecoder_Attention(\"GRU\",len(eng_index), 256, len(hindi_index), num_layers=1,dropout =0)\nloss_history = training_model(\"Adam\",X_train,Y_train,net, lr=0.01, no_of_batches= 5, batch_size = 64, display_freq=10, device = device_gpu)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:00:09.173587Z","iopub.execute_input":"2023-05-21T11:00:09.174112Z","iopub.status.idle":"2023-05-21T11:02:11.285353Z","shell.execute_reply.started":"2023-05-21T11:00:09.174072Z","shell.execute_reply":"2023-05-21T11:02:11.284359Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"net = EncoderDecoder_Attention(\"GRU\",len(eng_index), 256, len(hindi_index), num_layers=1,dropout =0)\nanswer = training_model(\"Adam\",X_train,Y_train,net, lr=0.01, no_of_batches= 50, batch_size = 512, display_freq=10, device = device_gpu)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T05:10:03.332055Z","iopub.execute_input":"2023-05-21T05:10:03.333057Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Iteration 19 Loss 0.05840916931629181 accuracy 0.19584911584279666\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\n\n20\n21\n22\n23\n24\n25\n26\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create the heatmap","metadata":{}},{"cell_type":"code","source":"#Function to create heatmap\n\ndef generate_heatmap(data, x_labels, y_labels):\n    fig, ax = plt.subplots()\n    print(x_labels)\n    # Create the heatmap\n\n    heatmap = ax.imshow(data, cmap='hot')\n    hindi_font = FontProperties(fname='/kaggle/input/file-to-convert/Mangal Regular.ttf')\n\n    # Set the x-axis and y-axis labels\n    ax.set_xticks(np.arange(len(x_labels)))\n    ax.set_yticks(np.arange(len(y_labels)))\n    ax.set_xticklabels(x_labels)\n    ax.set_yticklabels(y_labels,fontproperties=hindi_font)\n    wandb.init(project=\"Assignment3\")\n    wandb.log({\"heatmap\": wandb.Image(fig)})","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:06:50.933127Z","iopub.execute_input":"2023-05-21T06:06:50.933503Z","iopub.status.idle":"2023-05-21T06:06:50.939919Z","shell.execute_reply.started":"2023-05-21T06:06:50.933474Z","shell.execute_reply":"2023-05-21T06:06:50.938838Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"output , attention_weights = net.forward(word_representation('-p-',26,'wesiting', eng_index),len('वेस्टिंग'),asked = True)\nplt.imshow(attention_weights)\nprint(attention_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\n#ukhrul,उखरुल\nlst = []\n\nfor letter in 'wesiting':\n    lst.append(letter)\n \nprint(lst)\nlst1 = []\n \nfor letter in 'वेस्टिंग':\n    lst1.append(letter)\n\nprint(lst1,lst)\n\ngenerate_heatmap(attention_weights,lst,lst1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
